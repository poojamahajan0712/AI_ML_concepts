{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMBIfsMlPc1Aqd/Eea57sfy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/poojamahajan0712/AI_ML_concepts/blob/main/Quantization/Quantization_NB2_tensorflow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8fBD0cynTY9a"
      },
      "outputs": [],
      "source": [
        "#Reference - https://medium.com/game-of-bits/optimizing-tensorflow-models-using-quantization-fb4d09b46fac\n",
        "# https://ai.google.dev/edge/litert/models/post_training_quantization"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* key idea behind quantization - These techniques aim at providing smaller and faster models while keeping the performance of the models almost similar.\n",
        "* Post-training quantization -  the deep learning model is trained with FP-32 tensors and later converted to INT-8(or float-16) in order to get a smaller and faster model for deployment. it is a bit more stable than quantization aware training and easy to use.\n",
        "* In post-quantization techniques, we train the deep learning model normally and save the weights. These weights are later converted into TFLite format and quantized."
      ],
      "metadata": {
        "id": "7-fs0U9kVhOv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import load_digits\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.layers import Input, Dense, Conv2D, Flatten\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "dwhgWsWFVXKM"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#loading dataset\n",
        "digits = load_digits()\n",
        "images = digits['images']\n",
        "labels = digits['target']\n",
        "print (images.shape, labels.shape)\n",
        "\n",
        "#Splitting Data\n",
        "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.25, random_state=42)\n",
        "X_train = np.expand_dims(X_train, axis=-1)\n",
        "X_test = np.expand_dims(X_test, axis=-1)\n",
        "print (X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n",
        "\n",
        "#Encoding Labels\n",
        "def get_encoded_labels(target):\n",
        "    output=np.zeros((len(target),10))\n",
        "    for ix, value in enumerate(target):\n",
        "        output[ix][target[ix]] = 1\n",
        "    return output\n",
        "\n",
        "Y_train = get_encoded_labels(y_train)\n",
        "Y_test = get_encoded_labels(y_test)\n",
        "print (Y_train.shape, Y_test.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nVSTt-69WWtf",
        "outputId": "9e12ba28-b5ba-44a6-faf2-e535942ce14c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1797, 8, 8) (1797,)\n",
            "(1347, 8, 8, 1) (450, 8, 8, 1) (1347,) (450,)\n",
            "(1347, 10) (450, 10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "input_layer = Input(shape=(8, 8, 1))\n",
        "layer = Conv2D(64, (3,3), activation='relu')(input_layer)\n",
        "layer = Conv2D(32, (3,3), activation='relu')(layer)\n",
        "layer = Conv2D(32, (3,3), activation='relu')(layer)\n",
        "layer = Flatten()(layer)\n",
        "features = Dense(32, activation='relu')(layer)\n",
        "output = Dense(10, activation='softmax')(features)\n",
        "\n",
        "\n",
        "model = Model(inputs=input_layer, outputs=output)\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.summary()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "id": "7yfaHBd-WxUk",
        "outputId": "400a3403-05ac-4619-fa20-c8faeb7e5502"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m1\u001b[0m)             │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │             \u001b[38;5;34m640\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m32\u001b[0m)            │          \u001b[38;5;34m18,464\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m32\u001b[0m)            │           \u001b[38;5;34m9,248\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │           \u001b[38;5;34m4,128\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)                  │             \u001b[38;5;34m330\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)             │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">640</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)            │          <span style=\"color: #00af00; text-decoration-color: #00af00\">18,464</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">9,248</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">4,128</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">330</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m32,810\u001b[0m (128.16 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">32,810</span> (128.16 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m32,810\u001b[0m (128.16 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">32,810</span> (128.16 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train, Y_train, batch_size=32, epochs=10, validation_data=(X_test, Y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QddA5yDgZZFB",
        "outputId": "2ba9d317-1266-46b5-99bf-c9f690a695c7"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 40ms/step - accuracy: 0.3816 - loss: 1.7980 - val_accuracy: 0.8844 - val_loss: 0.3852\n",
            "Epoch 2/10\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.8820 - loss: 0.3848 - val_accuracy: 0.9467 - val_loss: 0.1853\n",
            "Epoch 3/10\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - accuracy: 0.9243 - loss: 0.2093 - val_accuracy: 0.9400 - val_loss: 0.2012\n",
            "Epoch 4/10\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 44ms/step - accuracy: 0.9455 - loss: 0.1583 - val_accuracy: 0.9733 - val_loss: 0.1180\n",
            "Epoch 5/10\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9669 - loss: 0.1053 - val_accuracy: 0.9644 - val_loss: 0.1074\n",
            "Epoch 6/10\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9575 - loss: 0.1213 - val_accuracy: 0.9778 - val_loss: 0.0717\n",
            "Epoch 7/10\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9910 - loss: 0.0438 - val_accuracy: 0.9844 - val_loss: 0.0651\n",
            "Epoch 8/10\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9950 - loss: 0.0238 - val_accuracy: 0.9844 - val_loss: 0.0629\n",
            "Epoch 9/10\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.9931 - loss: 0.0329 - val_accuracy: 0.9822 - val_loss: 0.0698\n",
            "Epoch 10/10\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9981 - loss: 0.0187 - val_accuracy: 0.9867 - val_loss: 0.0551\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x78a23dc1f0a0>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_test_accuracy(predictions, target):\n",
        "    correct = 0\n",
        "    for ix, pred in enumerate(predictions):\n",
        "        true_value = target[ix]\n",
        "        if pred[true_value] == max(pred):\n",
        "            correct += 1\n",
        "    return correct*100/len(target)\n",
        "predictions = model.predict(X_test)\n",
        "get_test_accuracy(predictions, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nnlu66yJZ5HX",
        "outputId": "7958b2f6-af6a-4c7e-ecb9-592ca816a706"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "98.66666666666667"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"saved_model.keras\")"
      ],
      "metadata": {
        "id": "o-XtJfmVVXgn"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Post training quantization"
      ],
      "metadata": {
        "id": "_048iylzb6LX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Dynamic range quantization -\n",
        "* Dynamic range quantization provides reduced memory usage and faster computation without you having to provide a representative dataset for calibration.\n",
        "- The key point here is that you don't need a representative dataset for calibration- This means you can apply dynamic range quantization directly to an already-trained model without needing additional data to fine-tune the quantization process\n",
        "* This type of quantization, statically quantizes only the weights from floating point to integer at conversion time, which provides 8-bits of precision\n",
        "* To further reduce latency during inference, \"dynamic-range\" operators dynamically quantize activations based on their range to 8-bits and perform computations with 8-bit weights and activations."
      ],
      "metadata": {
        "id": "Sn4HZw3VQpgF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## converting to tflite model\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "\n",
        "## applying quantization\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "tflite_quant_model = converter.convert()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yoTlkra2aKul",
        "outputId": "2fba105e-081e-47ad-aeb6-580c69da186c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved artifact at '/tmp/tmps7opvf22'. The following endpoints are available:\n",
            "\n",
            "* Endpoint 'serve'\n",
            "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 8, 8, 1), dtype=tf.float32, name='keras_tensor')\n",
            "Output Type:\n",
            "  TensorSpec(shape=(None, 10), dtype=tf.float32, name=None)\n",
            "Captures:\n",
            "  132638200706880: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132640508996672: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132638201247728: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132638201237696: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132638201285264: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132638201283152: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132638201284208: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132638201293712: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132638201294240: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132638201296528: TensorSpec(shape=(), dtype=tf.resource, name=None)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('quantized_model.tflite', 'wb') as f:\n",
        "    f.write(tflite_quant_model)"
      ],
      "metadata": {
        "id": "cgFBdscqS3uR"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "interpreter = tf.lite.Interpreter(model_path=\"quantized_model.tflite\")\n",
        "\n",
        "input_details = interpreter.get_input_details()\n",
        "output_details = interpreter.get_output_details()\n",
        "interpreter.allocate_tensors()\n",
        "\n",
        "print(input_details)\n",
        "print(output_details)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tjArgAZhTnvU",
        "outputId": "7ba697a3-473d-40c5-8d00-a7f19c9de996"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'name': 'serving_default_keras_tensor:0', 'index': 0, 'shape': array([1, 8, 8, 1], dtype=int32), 'shape_signature': array([-1,  8,  8,  1], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}]\n",
            "[{'name': 'StatefulPartitionedCall_1:0', 'index': 18, 'shape': array([ 1, 10], dtype=int32), 'shape_signature': array([-1, 10], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_details[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xqXLq-xvhgcd",
        "outputId": "88cc0ea3-cd83-4f68-abb8-d5af087b3ab2"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'name': 'serving_default_keras_tensor:0',\n",
              " 'index': 0,\n",
              " 'shape': array([1, 8, 8, 1], dtype=int32),\n",
              " 'shape_signature': array([-1,  8,  8,  1], dtype=int32),\n",
              " 'dtype': numpy.float32,\n",
              " 'quantization': (0.0, 0),\n",
              " 'quantization_parameters': {'scales': array([], dtype=float32),\n",
              "  'zero_points': array([], dtype=int32),\n",
              "  'quantized_dimension': 0},\n",
              " 'sparsity_parameters': {}}"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# interpreter.set_tensor() is used to set or assign the input data (the image) to the input tensor for the model to process.\n",
        "# After calling set_tensor() to assign the input, you need to invoke the model to run the inference and calculate the outputs.\n",
        "# get_tensor(): This method retrieves the output tensor after the inference is complete.After the model has run the inference, the results are stored in the output tensor, and get_tensor() allows you to access these results.\n",
        "\n",
        "\n",
        "predictions = []\n",
        "for img in X_test:\n",
        "    interpreter.set_tensor(input_details[0]['index'], [img.astype('float32')])\n",
        "    interpreter.invoke()\n",
        "    output_data = interpreter.get_tensor(output_details[0]['index'])\n",
        "    predictions.append(output_data[0])\n",
        "\n",
        "predictions = np.array(predictions)\n",
        "get_test_accuracy(predictions, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lW3UDlmiU4h6",
        "outputId": "311d3b44-edd2-4060-dfa5-3330bc7e5d5d"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "98.66666666666667"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "comparing model size"
      ],
      "metadata": {
        "id": "XJkbXkD_kA_Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_model_size(model_path):\n",
        "  model_size = os.path.getsize(model_path)\n",
        "  model_size_mb = model_size / (1024*1024)\n",
        "  print(f\"model size: {model_size_mb:.2f} MB\")"
      ],
      "metadata": {
        "id": "vIQ2TtsNVVOW"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_path = \"/content/saved_model.keras\"\n",
        "get_model_size(model_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O-Zvs76Ki8Ff",
        "outputId": "4ba8f157-48d0-40a6-c302-bfe19d0d9762"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model size: 0.41 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_path = \"/content/quantized_model.tflite\"\n",
        "get_model_size(model_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dpWiTKr1jU9V",
        "outputId": "7a81fadb-87d0-41f6-cfc2-e8f02b3113b7"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model size: 0.04 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Path to the quantized model\n",
        "model_path = 'quantized_model.tflite'\n",
        "# Get the size in bytes\n",
        "model_size = os.path.getsize(model_path)\n",
        "# Convert to kilobytes (KB) or megabytes (MB)\n",
        "model_size_mb = model_size_kb / 1024\n",
        "print(f\"Quantized model size: {model_size_mb:.2f} MB\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tTLM2q_OSCFw",
        "outputId": "beb68531-ce7f-4457-fd26-0e45f8d93ee7"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Quantized model size: 39.63 KB\n",
            "Quantized model size: 0.04 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jXk7rI9ZSElg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}